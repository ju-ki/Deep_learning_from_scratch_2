{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNによる文章生成\n",
    "* seq2seqというニューラルネットワークを使用する\n",
    "* これを使用することで機械翻訳やチャットボットなどの様々なアプリケーションで利用することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "os.chdir(\"./deep-learning-from-scratch-2-master/\")\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.functions import softmax\n",
    "from ch06.rnnlm import Rnnlm\n",
    "from ch06.better_rnnlm import BetterRnnlm\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "        \n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "            p = softmax(score.flatten())\n",
    "            \n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if(skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "        return word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you cancers bag seldom equitec disaster rest innocent competitiveness adopting payable anderson february balance prospective diversified guilty traveled altogether underwritten allied software armonk scoring antonio stressing sentenced trip guests massages become blunt power aimed citing warnings column bonn eat arising processors birth isolated margin mike prohibition tele-communications deviation undervalued charter reasons deficit deutsche sci plants passes thrown herald bidding exchange southam sudden ventures jolt trump fame lotus outlets grabbed quack unsecured slid cleared tied surprises richfield haul unilab recognition solidarity retire anniversary presented annuities theories internationally disks ghosts saul breath peter parcel yielded vowed pattern offensive seniors mayor succeed gaining\n"
     ]
    }
   ],
   "source": [
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data(\"train\")\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "\n",
    "start_word = \"you\"\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = [\"N\", \"<unk>\", \"$\"]\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(\" <eos>\", \".\\n\")\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you 'll take their own.\n",
      " the changes could recognized inches to the current wage on the minority of retail birds.\n",
      " this minister contained has come only from nine years and foam to a extension of more walking.\n",
      " identified he wrote the accord called working an agreement for a fast-growing meeting today for years.\n",
      " but now half of the planner whose washington-based offerings and television businesses firms with raising certain internal international loans.\n",
      " the experiment have turned restricted for the leaders of the certain warming said mr. roman wrote last month.\n",
      " mr. jones has told\n"
     ]
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data(\"train\")\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "model.load_params(\"./ch06/Rnnlm.pkl\")\n",
    "\n",
    "start_word = \"you\"\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = [\"N\", \"<unk>\", \"$\"]\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(\" <eos>\", \".\\n\")\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seq\n",
    "* 二つのRNNを利用する\n",
    "* Encoder-Decoderモデルとも言われている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7) (45000, 5)\n",
      "(5000, 7) (5000, 5)\n",
      "[11 12  1  2  0  0 11]\n",
      "[ 6  7  1 12  5]\n",
      "846+118\n",
      "_964 \n"
     ]
    }
   ],
   "source": [
    "from dataset import sequence\n",
    "\n",
    "(X_train, t_train), (X_test, t_test) = sequence.load_data(\"addition.txt\", seed=0)\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "print(X_train.shape, t_train.shape)\n",
    "print(X_test.shape, t_test.shape)\n",
    "\n",
    "print(X_train[0])\n",
    "print(t_train[0])\n",
    "\n",
    "print(\"\".join([id_to_char[c] for c in X_train[0]]))\n",
    "print(\"\".join([id_to_char[c] for c in t_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seqの実装\n",
    "#### Encoderクラス\n",
    "* Embedding層とLSTM層によって構成される。\n",
    "* Embedding層では文字を文字ベクトルに変換\n",
    "* LSTMレイヤでは時間方向に隠れ状態とセルを出力、上方向には隠れ状態のみを出力。その後廃棄\n",
    "* 最後の文字を処理した後、LSTMの隠れ状態hを出力。このhがDecoderに渡される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh\n",
    "\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "            out = self.lstm.forward(out)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(int(sample_id))\n",
    "\n",
    "        return sampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seqクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.base_model import *\n",
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "\n",
    "        h = self.encoder.forward(xs)\n",
    "        score = self.decoder.forward(decoder_xs, h)\n",
    "        loss = self.softmax.forward(score, decoder_ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n",
    "\n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs)\n",
    "        sampled = self.decoder.generate(h, start_id, sample_size)\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "os.chdir(\"./ch07/\")\n",
    "from peeky_seq2seq import PeekySeq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 2.56\n",
      "| epoch 1 |  iter 21 / 351 | time 0[s] | loss 2.53\n",
      "| epoch 1 |  iter 41 / 351 | time 1[s] | loss 2.17\n",
      "| epoch 1 |  iter 61 / 351 | time 2[s] | loss 1.96\n",
      "| epoch 1 |  iter 81 / 351 | time 3[s] | loss 1.92\n",
      "| epoch 1 |  iter 101 / 351 | time 4[s] | loss 1.87\n",
      "| epoch 1 |  iter 121 / 351 | time 5[s] | loss 1.85\n",
      "| epoch 1 |  iter 141 / 351 | time 6[s] | loss 1.83\n",
      "| epoch 1 |  iter 161 / 351 | time 7[s] | loss 1.79\n",
      "| epoch 1 |  iter 181 / 351 | time 8[s] | loss 1.77\n",
      "| epoch 1 |  iter 201 / 351 | time 9[s] | loss 1.77\n",
      "| epoch 1 |  iter 221 / 351 | time 10[s] | loss 1.76\n",
      "| epoch 1 |  iter 241 / 351 | time 11[s] | loss 1.76\n",
      "| epoch 1 |  iter 261 / 351 | time 12[s] | loss 1.76\n",
      "| epoch 1 |  iter 281 / 351 | time 13[s] | loss 1.75\n",
      "| epoch 1 |  iter 301 / 351 | time 14[s] | loss 1.74\n",
      "| epoch 1 |  iter 321 / 351 | time 15[s] | loss 1.75\n",
      "| epoch 1 |  iter 341 / 351 | time 16[s] | loss 1.74\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "val acc 0.180%\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.74\n",
      "| epoch 2 |  iter 21 / 351 | time 1[s] | loss 1.73\n",
      "| epoch 2 |  iter 41 / 351 | time 1[s] | loss 1.74\n",
      "| epoch 2 |  iter 61 / 351 | time 2[s] | loss 1.74\n",
      "| epoch 2 |  iter 81 / 351 | time 3[s] | loss 1.73\n",
      "| epoch 2 |  iter 101 / 351 | time 4[s] | loss 1.73\n",
      "| epoch 2 |  iter 121 / 351 | time 5[s] | loss 1.72\n",
      "| epoch 2 |  iter 141 / 351 | time 6[s] | loss 1.71\n",
      "| epoch 2 |  iter 161 / 351 | time 7[s] | loss 1.71\n",
      "| epoch 2 |  iter 181 / 351 | time 8[s] | loss 1.71\n",
      "| epoch 2 |  iter 201 / 351 | time 9[s] | loss 1.70\n",
      "| epoch 2 |  iter 221 / 351 | time 10[s] | loss 1.71\n",
      "| epoch 2 |  iter 241 / 351 | time 11[s] | loss 1.70\n",
      "| epoch 2 |  iter 261 / 351 | time 12[s] | loss 1.69\n",
      "| epoch 2 |  iter 281 / 351 | time 13[s] | loss 1.69\n",
      "| epoch 2 |  iter 301 / 351 | time 14[s] | loss 1.69\n",
      "| epoch 2 |  iter 321 / 351 | time 15[s] | loss 1.68\n",
      "| epoch 2 |  iter 341 / 351 | time 16[s] | loss 1.67\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 994 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 700 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1544\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "val acc 0.220%\n",
      "| epoch 3 |  iter 1 / 351 | time 0[s] | loss 1.66\n",
      "| epoch 3 |  iter 21 / 351 | time 1[s] | loss 1.66\n",
      "| epoch 3 |  iter 41 / 351 | time 2[s] | loss 1.65\n",
      "| epoch 3 |  iter 61 / 351 | time 3[s] | loss 1.63\n",
      "| epoch 3 |  iter 81 / 351 | time 4[s] | loss 1.62\n",
      "| epoch 3 |  iter 101 / 351 | time 4[s] | loss 1.62\n",
      "| epoch 3 |  iter 121 / 351 | time 5[s] | loss 1.60\n",
      "| epoch 3 |  iter 141 / 351 | time 6[s] | loss 1.59\n",
      "| epoch 3 |  iter 161 / 351 | time 7[s] | loss 1.57\n",
      "| epoch 3 |  iter 181 / 351 | time 8[s] | loss 1.57\n",
      "| epoch 3 |  iter 201 / 351 | time 9[s] | loss 1.56\n",
      "| epoch 3 |  iter 221 / 351 | time 10[s] | loss 1.54\n",
      "| epoch 3 |  iter 241 / 351 | time 11[s] | loss 1.52\n",
      "| epoch 3 |  iter 261 / 351 | time 12[s] | loss 1.52\n",
      "| epoch 3 |  iter 281 / 351 | time 13[s] | loss 1.52\n",
      "| epoch 3 |  iter 301 / 351 | time 14[s] | loss 1.50\n",
      "| epoch 3 |  iter 321 / 351 | time 15[s] | loss 1.49\n",
      "| epoch 3 |  iter 341 / 351 | time 16[s] | loss 1.48\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 108 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 648 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 138 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 448 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 848 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1011\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1373\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 348 \n",
      "---\n",
      "val acc 0.560%\n",
      "| epoch 4 |  iter 1 / 351 | time 0[s] | loss 1.47\n",
      "| epoch 4 |  iter 21 / 351 | time 1[s] | loss 1.46\n",
      "| epoch 4 |  iter 41 / 351 | time 2[s] | loss 1.44\n",
      "| epoch 4 |  iter 61 / 351 | time 2[s] | loss 1.43\n",
      "| epoch 4 |  iter 81 / 351 | time 4[s] | loss 1.42\n",
      "| epoch 4 |  iter 101 / 351 | time 4[s] | loss 1.41\n",
      "| epoch 4 |  iter 121 / 351 | time 5[s] | loss 1.40\n",
      "| epoch 4 |  iter 141 / 351 | time 6[s] | loss 1.40\n",
      "| epoch 4 |  iter 161 / 351 | time 7[s] | loss 1.38\n",
      "| epoch 4 |  iter 181 / 351 | time 8[s] | loss 1.38\n",
      "| epoch 4 |  iter 201 / 351 | time 9[s] | loss 1.37\n",
      "| epoch 4 |  iter 221 / 351 | time 10[s] | loss 1.35\n",
      "| epoch 4 |  iter 241 / 351 | time 11[s] | loss 1.33\n",
      "| epoch 4 |  iter 261 / 351 | time 12[s] | loss 1.33\n",
      "| epoch 4 |  iter 281 / 351 | time 13[s] | loss 1.33\n",
      "| epoch 4 |  iter 301 / 351 | time 14[s] | loss 1.32\n",
      "| epoch 4 |  iter 321 / 351 | time 15[s] | loss 1.31\n",
      "| epoch 4 |  iter 341 / 351 | time 16[s] | loss 1.30\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 146 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1189\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 432 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1002\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1406\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 202 \n",
      "---\n",
      "val acc 1.060%\n",
      "| epoch 5 |  iter 1 / 351 | time 0[s] | loss 1.28\n",
      "| epoch 5 |  iter 21 / 351 | time 1[s] | loss 1.29\n",
      "| epoch 5 |  iter 41 / 351 | time 2[s] | loss 1.28\n",
      "| epoch 5 |  iter 61 / 351 | time 3[s] | loss 1.27\n",
      "| epoch 5 |  iter 81 / 351 | time 3[s] | loss 1.27\n",
      "| epoch 5 |  iter 101 / 351 | time 4[s] | loss 1.26\n",
      "| epoch 5 |  iter 121 / 351 | time 5[s] | loss 1.26\n",
      "| epoch 5 |  iter 141 / 351 | time 6[s] | loss 1.27\n",
      "| epoch 5 |  iter 161 / 351 | time 7[s] | loss 1.26\n",
      "| epoch 5 |  iter 181 / 351 | time 8[s] | loss 1.25\n",
      "| epoch 5 |  iter 201 / 351 | time 9[s] | loss 1.23\n",
      "| epoch 5 |  iter 221 / 351 | time 10[s] | loss 1.22\n",
      "| epoch 5 |  iter 241 / 351 | time 11[s] | loss 1.21\n",
      "| epoch 5 |  iter 261 / 351 | time 12[s] | loss 1.21\n",
      "| epoch 5 |  iter 281 / 351 | time 13[s] | loss 1.21\n",
      "| epoch 5 |  iter 301 / 351 | time 14[s] | loss 1.20\n",
      "| epoch 5 |  iter 321 / 351 | time 15[s] | loss 1.19\n",
      "| epoch 5 |  iter 341 / 351 | time 16[s] | loss 1.18\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 145 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1168\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 192 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 431 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 895 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1015\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1493\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 891 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 221 \n",
      "---\n",
      "val acc 2.260%\n",
      "| epoch 6 |  iter 1 / 351 | time 0[s] | loss 1.17\n",
      "| epoch 6 |  iter 21 / 351 | time 1[s] | loss 1.17\n",
      "| epoch 6 |  iter 41 / 351 | time 2[s] | loss 1.18\n",
      "| epoch 6 |  iter 61 / 351 | time 3[s] | loss 1.17\n",
      "| epoch 6 |  iter 81 / 351 | time 4[s] | loss 1.16\n",
      "| epoch 6 |  iter 101 / 351 | time 5[s] | loss 1.16\n",
      "| epoch 6 |  iter 121 / 351 | time 6[s] | loss 1.16\n",
      "| epoch 6 |  iter 141 / 351 | time 7[s] | loss 1.14\n",
      "| epoch 6 |  iter 161 / 351 | time 8[s] | loss 1.14\n",
      "| epoch 6 |  iter 181 / 351 | time 9[s] | loss 1.13\n",
      "| epoch 6 |  iter 201 / 351 | time 10[s] | loss 1.15\n",
      "| epoch 6 |  iter 221 / 351 | time 11[s] | loss 1.13\n",
      "| epoch 6 |  iter 241 / 351 | time 11[s] | loss 1.12\n",
      "| epoch 6 |  iter 261 / 351 | time 12[s] | loss 1.12\n",
      "| epoch 6 |  iter 281 / 351 | time 13[s] | loss 1.13\n",
      "| epoch 6 |  iter 301 / 351 | time 14[s] | loss 1.11\n",
      "| epoch 6 |  iter 321 / 351 | time 15[s] | loss 1.10\n",
      "| epoch 6 |  iter 341 / 351 | time 16[s] | loss 1.10\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 660 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 411 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 847 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1011\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1411\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 857 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 207 \n",
      "---\n",
      "val acc 2.560%\n",
      "| epoch 7 |  iter 1 / 351 | time 0[s] | loss 1.11\n",
      "| epoch 7 |  iter 21 / 351 | time 1[s] | loss 1.10\n",
      "| epoch 7 |  iter 41 / 351 | time 2[s] | loss 1.11\n",
      "| epoch 7 |  iter 61 / 351 | time 3[s] | loss 1.11\n",
      "| epoch 7 |  iter 81 / 351 | time 4[s] | loss 1.10\n",
      "| epoch 7 |  iter 101 / 351 | time 5[s] | loss 1.11\n",
      "| epoch 7 |  iter 121 / 351 | time 6[s] | loss 1.08\n",
      "| epoch 7 |  iter 141 / 351 | time 7[s] | loss 1.07\n",
      "| epoch 7 |  iter 161 / 351 | time 7[s] | loss 1.08\n",
      "| epoch 7 |  iter 181 / 351 | time 8[s] | loss 1.07\n",
      "| epoch 7 |  iter 201 / 351 | time 9[s] | loss 1.06\n",
      "| epoch 7 |  iter 221 / 351 | time 10[s] | loss 1.07\n",
      "| epoch 7 |  iter 241 / 351 | time 11[s] | loss 1.06\n",
      "| epoch 7 |  iter 261 / 351 | time 12[s] | loss 1.06\n",
      "| epoch 7 |  iter 281 / 351 | time 13[s] | loss 1.07\n",
      "| epoch 7 |  iter 301 / 351 | time 14[s] | loss 1.05\n",
      "| epoch 7 |  iter 321 / 351 | time 15[s] | loss 1.06\n",
      "| epoch 7 |  iter 341 / 351 | time 16[s] | loss 1.04\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 156 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 656 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 141 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 418 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 864 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1409\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 227 \n",
      "---\n",
      "val acc 3.820%\n",
      "| epoch 8 |  iter 1 / 351 | time 0[s] | loss 1.05\n",
      "| epoch 8 |  iter 21 / 351 | time 1[s] | loss 1.03\n",
      "| epoch 8 |  iter 41 / 351 | time 2[s] | loss 1.04\n",
      "| epoch 8 |  iter 61 / 351 | time 3[s] | loss 1.04\n",
      "| epoch 8 |  iter 81 / 351 | time 4[s] | loss 1.04\n",
      "| epoch 8 |  iter 101 / 351 | time 5[s] | loss 1.04\n",
      "| epoch 8 |  iter 121 / 351 | time 6[s] | loss 1.02\n",
      "| epoch 8 |  iter 141 / 351 | time 7[s] | loss 1.07\n",
      "| epoch 8 |  iter 161 / 351 | time 8[s] | loss 1.05\n",
      "| epoch 8 |  iter 181 / 351 | time 9[s] | loss 1.04\n",
      "| epoch 8 |  iter 201 / 351 | time 10[s] | loss 1.02\n",
      "| epoch 8 |  iter 221 / 351 | time 11[s] | loss 1.02\n",
      "| epoch 8 |  iter 241 / 351 | time 11[s] | loss 1.02\n",
      "| epoch 8 |  iter 261 / 351 | time 12[s] | loss 1.02\n",
      "| epoch 8 |  iter 281 / 351 | time 14[s] | loss 1.00\n",
      "| epoch 8 |  iter 301 / 351 | time 15[s] | loss 1.02\n",
      "| epoch 8 |  iter 321 / 351 | time 16[s] | loss 1.03\n",
      "| epoch 8 |  iter 341 / 351 | time 16[s] | loss 1.04\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 402 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 873 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1073\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1449\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 227 \n",
      "---\n",
      "val acc 2.920%\n",
      "| epoch 9 |  iter 1 / 351 | time 0[s] | loss 1.05\n",
      "| epoch 9 |  iter 21 / 351 | time 1[s] | loss 1.02\n",
      "| epoch 9 |  iter 41 / 351 | time 2[s] | loss 0.99\n",
      "| epoch 9 |  iter 61 / 351 | time 2[s] | loss 1.00\n",
      "| epoch 9 |  iter 81 / 351 | time 3[s] | loss 1.00\n",
      "| epoch 9 |  iter 101 / 351 | time 4[s] | loss 1.04\n",
      "| epoch 9 |  iter 121 / 351 | time 5[s] | loss 1.00\n",
      "| epoch 9 |  iter 141 / 351 | time 6[s] | loss 0.99\n",
      "| epoch 9 |  iter 161 / 351 | time 7[s] | loss 1.02\n",
      "| epoch 9 |  iter 181 / 351 | time 8[s] | loss 0.98\n",
      "| epoch 9 |  iter 201 / 351 | time 9[s] | loss 0.99\n",
      "| epoch 9 |  iter 221 / 351 | time 10[s] | loss 0.98\n",
      "| epoch 9 |  iter 241 / 351 | time 11[s] | loss 0.99\n",
      "| epoch 9 |  iter 261 / 351 | time 12[s] | loss 0.99\n",
      "| epoch 9 |  iter 281 / 351 | time 13[s] | loss 0.99\n",
      "| epoch 9 |  iter 301 / 351 | time 14[s] | loss 1.00\n",
      "| epoch 9 |  iter 321 / 351 | time 15[s] | loss 0.98\n",
      "| epoch 9 |  iter 341 / 351 | time 16[s] | loss 0.97\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1121\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 418 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 847 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 847 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 228 \n",
      "---\n",
      "val acc 4.820%\n",
      "| epoch 10 |  iter 1 / 351 | time 0[s] | loss 0.95\n",
      "| epoch 10 |  iter 21 / 351 | time 1[s] | loss 0.97\n",
      "| epoch 10 |  iter 41 / 351 | time 1[s] | loss 1.01\n",
      "| epoch 10 |  iter 61 / 351 | time 2[s] | loss 1.00\n",
      "| epoch 10 |  iter 81 / 351 | time 3[s] | loss 1.00\n",
      "| epoch 10 |  iter 101 / 351 | time 5[s] | loss 0.99\n",
      "| epoch 10 |  iter 121 / 351 | time 6[s] | loss 0.96\n",
      "| epoch 10 |  iter 141 / 351 | time 7[s] | loss 1.04\n",
      "| epoch 10 |  iter 161 / 351 | time 8[s] | loss 1.06\n",
      "| epoch 10 |  iter 181 / 351 | time 9[s] | loss 1.06\n",
      "| epoch 10 |  iter 201 / 351 | time 10[s] | loss 1.05\n",
      "| epoch 10 |  iter 221 / 351 | time 11[s] | loss 1.04\n",
      "| epoch 10 |  iter 241 / 351 | time 13[s] | loss 0.99\n",
      "| epoch 10 |  iter 261 / 351 | time 14[s] | loss 0.99\n",
      "| epoch 10 |  iter 281 / 351 | time 15[s] | loss 0.96\n",
      "| epoch 10 |  iter 301 / 351 | time 16[s] | loss 0.96\n",
      "| epoch 10 |  iter 321 / 351 | time 17[s] | loss 0.96\n",
      "| epoch 10 |  iter 341 / 351 | time 18[s] | loss 0.95\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 660 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 149 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 407 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 237 \n",
      "---\n",
      "val acc 4.820%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# Reverse input? =================================================\n",
    "is_reverse = False  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "# Normal or Peeky? ==============================================\n",
    "model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "\n",
    "# グラフの描画\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seqの改良\n",
    "#### 入力データの反転(先ほどのコードでreveseをTrueに変更)\n",
    "* https://arxiv.org/pdf/1409.3215.pdf こちらで紹介されていた\n",
    "#### 覗き見\n",
    "* Encoderには入力データを固定長のベクトルhに変換（この中にDecoderにとって重要な情報がすべて詰まっている）\n",
    "* LSTMレイヤのみがベクトルhを利用している。\n",
    "* https://arxiv.org/pdf/1406.1078.pdf　覗き見の論文\n",
    "* 重要な情報を共有する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 2.56\n",
      "| epoch 1 |  iter 21 / 351 | time 0[s] | loss 2.52\n",
      "| epoch 1 |  iter 41 / 351 | time 1[s] | loss 2.17\n",
      "| epoch 1 |  iter 61 / 351 | time 2[s] | loss 1.96\n",
      "| epoch 1 |  iter 81 / 351 | time 3[s] | loss 1.91\n",
      "| epoch 1 |  iter 101 / 351 | time 4[s] | loss 1.87\n",
      "| epoch 1 |  iter 121 / 351 | time 5[s] | loss 1.86\n",
      "| epoch 1 |  iter 141 / 351 | time 5[s] | loss 1.84\n",
      "| epoch 1 |  iter 161 / 351 | time 6[s] | loss 1.80\n",
      "| epoch 1 |  iter 181 / 351 | time 7[s] | loss 1.78\n",
      "| epoch 1 |  iter 201 / 351 | time 8[s] | loss 1.77\n",
      "| epoch 1 |  iter 221 / 351 | time 9[s] | loss 1.77\n",
      "| epoch 1 |  iter 241 / 351 | time 11[s] | loss 1.76\n",
      "| epoch 1 |  iter 261 / 351 | time 11[s] | loss 1.75\n",
      "| epoch 1 |  iter 281 / 351 | time 12[s] | loss 1.74\n",
      "| epoch 1 |  iter 301 / 351 | time 13[s] | loss 1.74\n",
      "| epoch 1 |  iter 321 / 351 | time 14[s] | loss 1.74\n",
      "| epoch 1 |  iter 341 / 351 | time 15[s] | loss 1.73\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 703 \n",
      "---\n",
      "val acc 0.120%\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.73\n",
      "| epoch 2 |  iter 21 / 351 | time 1[s] | loss 1.72\n",
      "| epoch 2 |  iter 41 / 351 | time 2[s] | loss 1.72\n",
      "| epoch 2 |  iter 61 / 351 | time 3[s] | loss 1.72\n",
      "| epoch 2 |  iter 81 / 351 | time 4[s] | loss 1.70\n",
      "| epoch 2 |  iter 101 / 351 | time 5[s] | loss 1.70\n",
      "| epoch 2 |  iter 121 / 351 | time 6[s] | loss 1.69\n",
      "| epoch 2 |  iter 141 / 351 | time 7[s] | loss 1.68\n",
      "| epoch 2 |  iter 161 / 351 | time 8[s] | loss 1.67\n",
      "| epoch 2 |  iter 181 / 351 | time 9[s] | loss 1.66\n",
      "| epoch 2 |  iter 201 / 351 | time 10[s] | loss 1.66\n",
      "| epoch 2 |  iter 221 / 351 | time 11[s] | loss 1.65\n",
      "| epoch 2 |  iter 241 / 351 | time 12[s] | loss 1.63\n",
      "| epoch 2 |  iter 261 / 351 | time 13[s] | loss 1.62\n",
      "| epoch 2 |  iter 281 / 351 | time 14[s] | loss 1.61\n",
      "| epoch 2 |  iter 301 / 351 | time 15[s] | loss 1.60\n",
      "| epoch 2 |  iter 321 / 351 | time 16[s] | loss 1.58\n",
      "| epoch 2 |  iter 341 / 351 | time 17[s] | loss 1.56\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 690 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 470 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 700 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1444\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 700 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 370 \n",
      "---\n",
      "val acc 0.400%\n",
      "| epoch 3 |  iter 1 / 351 | time 0[s] | loss 1.52\n",
      "| epoch 3 |  iter 21 / 351 | time 0[s] | loss 1.53\n",
      "| epoch 3 |  iter 41 / 351 | time 1[s] | loss 1.51\n",
      "| epoch 3 |  iter 61 / 351 | time 2[s] | loss 1.49\n",
      "| epoch 3 |  iter 81 / 351 | time 3[s] | loss 1.47\n",
      "| epoch 3 |  iter 101 / 351 | time 4[s] | loss 1.45\n",
      "| epoch 3 |  iter 121 / 351 | time 5[s] | loss 1.44\n",
      "| epoch 3 |  iter 141 / 351 | time 6[s] | loss 1.42\n",
      "| epoch 3 |  iter 161 / 351 | time 7[s] | loss 1.40\n",
      "| epoch 3 |  iter 181 / 351 | time 8[s] | loss 1.38\n",
      "| epoch 3 |  iter 201 / 351 | time 9[s] | loss 1.37\n",
      "| epoch 3 |  iter 221 / 351 | time 10[s] | loss 1.35\n",
      "| epoch 3 |  iter 241 / 351 | time 10[s] | loss 1.33\n",
      "| epoch 3 |  iter 261 / 351 | time 13[s] | loss 1.32\n",
      "| epoch 3 |  iter 281 / 351 | time 14[s] | loss 1.30\n",
      "| epoch 3 |  iter 301 / 351 | time 15[s] | loss 1.29\n",
      "| epoch 3 |  iter 321 / 351 | time 16[s] | loss 1.28\n",
      "| epoch 3 |  iter 341 / 351 | time 17[s] | loss 1.27\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1148\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 382 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 818 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1008\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1434\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 838 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 202 \n",
      "---\n",
      "val acc 1.940%\n",
      "| epoch 4 |  iter 1 / 351 | time 0[s] | loss 1.26\n",
      "| epoch 4 |  iter 21 / 351 | time 0[s] | loss 1.25\n",
      "| epoch 4 |  iter 41 / 351 | time 1[s] | loss 1.23\n",
      "| epoch 4 |  iter 61 / 351 | time 4[s] | loss 1.22\n",
      "| epoch 4 |  iter 81 / 351 | time 5[s] | loss 1.20\n",
      "| epoch 4 |  iter 101 / 351 | time 6[s] | loss 1.19\n",
      "| epoch 4 |  iter 121 / 351 | time 8[s] | loss 1.18\n",
      "| epoch 4 |  iter 141 / 351 | time 9[s] | loss 1.17\n",
      "| epoch 4 |  iter 161 / 351 | time 10[s] | loss 1.15\n",
      "| epoch 4 |  iter 181 / 351 | time 12[s] | loss 1.13\n",
      "| epoch 4 |  iter 201 / 351 | time 13[s] | loss 1.12\n",
      "| epoch 4 |  iter 221 / 351 | time 14[s] | loss 1.11\n",
      "| epoch 4 |  iter 241 / 351 | time 15[s] | loss 1.09\n",
      "| epoch 4 |  iter 261 / 351 | time 16[s] | loss 1.08\n",
      "| epoch 4 |  iter 281 / 351 | time 18[s] | loss 1.07\n",
      "| epoch 4 |  iter 301 / 351 | time 20[s] | loss 1.07\n",
      "| epoch 4 |  iter 321 / 351 | time 22[s] | loss 1.05\n",
      "| epoch 4 |  iter 341 / 351 | time 23[s] | loss 1.03\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1196\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 896 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1010\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1496\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "val acc 5.780%\n",
      "| epoch 5 |  iter 1 / 351 | time 0[s] | loss 1.01\n",
      "| epoch 5 |  iter 21 / 351 | time 1[s] | loss 1.01\n",
      "| epoch 5 |  iter 41 / 351 | time 2[s] | loss 1.00\n",
      "| epoch 5 |  iter 61 / 351 | time 3[s] | loss 0.99\n",
      "| epoch 5 |  iter 81 / 351 | time 4[s] | loss 0.97\n",
      "| epoch 5 |  iter 101 / 351 | time 5[s] | loss 0.95\n",
      "| epoch 5 |  iter 121 / 351 | time 6[s] | loss 0.95\n",
      "| epoch 5 |  iter 141 / 351 | time 7[s] | loss 0.94\n",
      "| epoch 5 |  iter 161 / 351 | time 9[s] | loss 0.93\n",
      "| epoch 5 |  iter 181 / 351 | time 10[s] | loss 0.93\n",
      "| epoch 5 |  iter 201 / 351 | time 11[s] | loss 0.91\n",
      "| epoch 5 |  iter 221 / 351 | time 12[s] | loss 0.89\n",
      "| epoch 5 |  iter 241 / 351 | time 14[s] | loss 0.89\n",
      "| epoch 5 |  iter 261 / 351 | time 15[s] | loss 0.88\n",
      "| epoch 5 |  iter 281 / 351 | time 16[s] | loss 0.87\n",
      "| epoch 5 |  iter 301 / 351 | time 18[s] | loss 0.86\n",
      "| epoch 5 |  iter 321 / 351 | time 19[s] | loss 0.85\n",
      "| epoch 5 |  iter 341 / 351 | time 20[s] | loss 0.84\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1192\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 860 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1066\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1414\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 232 \n",
      "---\n",
      "val acc 12.460%\n",
      "| epoch 6 |  iter 1 / 351 | time 0[s] | loss 0.86\n",
      "| epoch 6 |  iter 21 / 351 | time 1[s] | loss 0.82\n",
      "| epoch 6 |  iter 41 / 351 | time 2[s] | loss 0.82\n",
      "| epoch 6 |  iter 61 / 351 | time 3[s] | loss 0.81\n",
      "| epoch 6 |  iter 81 / 351 | time 4[s] | loss 0.80\n",
      "| epoch 6 |  iter 101 / 351 | time 5[s] | loss 0.80\n",
      "| epoch 6 |  iter 121 / 351 | time 6[s] | loss 0.79\n",
      "| epoch 6 |  iter 141 / 351 | time 7[s] | loss 0.78\n",
      "| epoch 6 |  iter 161 / 351 | time 8[s] | loss 0.77\n",
      "| epoch 6 |  iter 181 / 351 | time 9[s] | loss 0.77\n",
      "| epoch 6 |  iter 201 / 351 | time 10[s] | loss 0.78\n",
      "| epoch 6 |  iter 221 / 351 | time 11[s] | loss 0.76\n",
      "| epoch 6 |  iter 241 / 351 | time 12[s] | loss 0.75\n",
      "| epoch 6 |  iter 261 / 351 | time 13[s] | loss 0.74\n",
      "| epoch 6 |  iter 281 / 351 | time 14[s] | loss 0.73\n",
      "| epoch 6 |  iter 301 / 351 | time 15[s] | loss 0.73\n",
      "| epoch 6 |  iter 321 / 351 | time 16[s] | loss 0.72\n",
      "| epoch 6 |  iter 341 / 351 | time 17[s] | loss 0.72\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1141\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 661 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 851 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1061\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1391\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 234 \n",
      "---\n",
      "val acc 14.260%\n",
      "| epoch 7 |  iter 1 / 351 | time 0[s] | loss 0.71\n",
      "| epoch 7 |  iter 21 / 351 | time 1[s] | loss 0.71\n",
      "| epoch 7 |  iter 41 / 351 | time 2[s] | loss 0.70\n",
      "| epoch 7 |  iter 61 / 351 | time 3[s] | loss 0.70\n",
      "| epoch 7 |  iter 81 / 351 | time 4[s] | loss 0.68\n",
      "| epoch 7 |  iter 101 / 351 | time 5[s] | loss 0.68\n",
      "| epoch 7 |  iter 121 / 351 | time 6[s] | loss 0.67\n",
      "| epoch 7 |  iter 141 / 351 | time 7[s] | loss 0.67\n",
      "| epoch 7 |  iter 161 / 351 | time 8[s] | loss 0.67\n",
      "| epoch 7 |  iter 181 / 351 | time 9[s] | loss 0.66\n",
      "| epoch 7 |  iter 201 / 351 | time 10[s] | loss 0.66\n",
      "| epoch 7 |  iter 221 / 351 | time 11[s] | loss 0.66\n",
      "| epoch 7 |  iter 241 / 351 | time 12[s] | loss 0.64\n",
      "| epoch 7 |  iter 261 / 351 | time 13[s] | loss 0.65\n",
      "| epoch 7 |  iter 281 / 351 | time 14[s] | loss 0.64\n",
      "| epoch 7 |  iter 301 / 351 | time 15[s] | loss 0.63\n",
      "| epoch 7 |  iter 321 / 351 | time 16[s] | loss 0.63\n",
      "| epoch 7 |  iter 341 / 351 | time 17[s] | loss 0.62\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1142\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1144\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1431\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "val acc 17.500%\n",
      "| epoch 8 |  iter 1 / 351 | time 0[s] | loss 0.66\n",
      "| epoch 8 |  iter 21 / 351 | time 1[s] | loss 0.61\n",
      "| epoch 8 |  iter 41 / 351 | time 2[s] | loss 0.62\n",
      "| epoch 8 |  iter 61 / 351 | time 3[s] | loss 0.61\n",
      "| epoch 8 |  iter 81 / 351 | time 4[s] | loss 0.61\n",
      "| epoch 8 |  iter 101 / 351 | time 5[s] | loss 0.61\n",
      "| epoch 8 |  iter 121 / 351 | time 6[s] | loss 0.60\n",
      "| epoch 8 |  iter 141 / 351 | time 7[s] | loss 0.60\n",
      "| epoch 8 |  iter 161 / 351 | time 8[s] | loss 0.59\n",
      "| epoch 8 |  iter 181 / 351 | time 9[s] | loss 0.58\n",
      "| epoch 8 |  iter 201 / 351 | time 10[s] | loss 0.59\n",
      "| epoch 8 |  iter 221 / 351 | time 11[s] | loss 0.60\n",
      "| epoch 8 |  iter 241 / 351 | time 12[s] | loss 0.59\n",
      "| epoch 8 |  iter 261 / 351 | time 13[s] | loss 0.58\n",
      "| epoch 8 |  iter 281 / 351 | time 14[s] | loss 0.59\n",
      "| epoch 8 |  iter 301 / 351 | time 15[s] | loss 0.58\n",
      "| epoch 8 |  iter 321 / 351 | time 16[s] | loss 0.57\n",
      "| epoch 8 |  iter 341 / 351 | time 17[s] | loss 0.57\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1134\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 759 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1431\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 866 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 238 \n",
      "---\n",
      "val acc 23.080%\n",
      "| epoch 9 |  iter 1 / 351 | time 0[s] | loss 0.55\n",
      "| epoch 9 |  iter 21 / 351 | time 1[s] | loss 0.56\n",
      "| epoch 9 |  iter 41 / 351 | time 2[s] | loss 0.56\n",
      "| epoch 9 |  iter 61 / 351 | time 3[s] | loss 0.55\n",
      "| epoch 9 |  iter 81 / 351 | time 4[s] | loss 0.54\n",
      "| epoch 9 |  iter 101 / 351 | time 5[s] | loss 0.55\n",
      "| epoch 9 |  iter 121 / 351 | time 6[s] | loss 0.55\n",
      "| epoch 9 |  iter 141 / 351 | time 7[s] | loss 0.54\n",
      "| epoch 9 |  iter 161 / 351 | time 8[s] | loss 0.55\n",
      "| epoch 9 |  iter 181 / 351 | time 9[s] | loss 0.53\n",
      "| epoch 9 |  iter 201 / 351 | time 10[s] | loss 0.54\n",
      "| epoch 9 |  iter 221 / 351 | time 11[s] | loss 0.54\n",
      "| epoch 9 |  iter 241 / 351 | time 12[s] | loss 0.53\n",
      "| epoch 9 |  iter 261 / 351 | time 13[s] | loss 0.53\n",
      "| epoch 9 |  iter 281 / 351 | time 14[s] | loss 0.54\n",
      "| epoch 9 |  iter 301 / 351 | time 15[s] | loss 0.54\n",
      "| epoch 9 |  iter 321 / 351 | time 16[s] | loss 0.53\n",
      "| epoch 9 |  iter 341 / 351 | time 17[s] | loss 0.53\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1142\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 664 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 854 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 238 \n",
      "---\n",
      "val acc 26.520%\n",
      "| epoch 10 |  iter 1 / 351 | time 0[s] | loss 0.50\n",
      "| epoch 10 |  iter 21 / 351 | time 1[s] | loss 0.51\n",
      "| epoch 10 |  iter 41 / 351 | time 2[s] | loss 0.52\n",
      "| epoch 10 |  iter 61 / 351 | time 3[s] | loss 0.55\n",
      "| epoch 10 |  iter 81 / 351 | time 4[s] | loss 0.52\n",
      "| epoch 10 |  iter 101 / 351 | time 5[s] | loss 0.51\n",
      "| epoch 10 |  iter 121 / 351 | time 6[s] | loss 0.50\n",
      "| epoch 10 |  iter 141 / 351 | time 8[s] | loss 0.51\n",
      "| epoch 10 |  iter 161 / 351 | time 9[s] | loss 0.52\n",
      "| epoch 10 |  iter 181 / 351 | time 10[s] | loss 0.53\n",
      "| epoch 10 |  iter 201 / 351 | time 11[s] | loss 0.50\n",
      "| epoch 10 |  iter 221 / 351 | time 12[s] | loss 0.50\n",
      "| epoch 10 |  iter 241 / 351 | time 13[s] | loss 0.50\n",
      "| epoch 10 |  iter 261 / 351 | time 14[s] | loss 0.50\n",
      "| epoch 10 |  iter 281 / 351 | time 15[s] | loss 0.49\n",
      "| epoch 10 |  iter 301 / 351 | time 16[s] | loss 0.48\n",
      "| epoch 10 |  iter 321 / 351 | time 17[s] | loss 0.48\n",
      "| epoch 10 |  iter 341 / 351 | time 18[s] | loss 0.48\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 664 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1054\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1431\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "val acc 29.820%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# Reverse input? =================================================\n",
    "is_reverse = True  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "# Normal or Peeky? ==============================================\n",
    "model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "\n",
    "# グラフの描画\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 2.57\n",
      "| epoch 1 |  iter 21 / 351 | time 0[s] | loss 2.48\n",
      "| epoch 1 |  iter 41 / 351 | time 1[s] | loss 2.20\n",
      "| epoch 1 |  iter 61 / 351 | time 2[s] | loss 1.99\n",
      "| epoch 1 |  iter 81 / 351 | time 3[s] | loss 1.89\n",
      "| epoch 1 |  iter 101 / 351 | time 4[s] | loss 1.82\n",
      "| epoch 1 |  iter 121 / 351 | time 5[s] | loss 1.82\n",
      "| epoch 1 |  iter 141 / 351 | time 7[s] | loss 1.80\n",
      "| epoch 1 |  iter 161 / 351 | time 8[s] | loss 1.79\n",
      "| epoch 1 |  iter 181 / 351 | time 9[s] | loss 1.78\n",
      "| epoch 1 |  iter 201 / 351 | time 10[s] | loss 1.77\n",
      "| epoch 1 |  iter 221 / 351 | time 11[s] | loss 1.76\n",
      "| epoch 1 |  iter 241 / 351 | time 12[s] | loss 1.76\n",
      "| epoch 1 |  iter 261 / 351 | time 13[s] | loss 1.75\n",
      "| epoch 1 |  iter 281 / 351 | time 14[s] | loss 1.74\n",
      "| epoch 1 |  iter 301 / 351 | time 15[s] | loss 1.74\n",
      "| epoch 1 |  iter 321 / 351 | time 16[s] | loss 1.73\n",
      "| epoch 1 |  iter 341 / 351 | time 17[s] | loss 1.73\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1013\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 102 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 1023\n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 1023\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1023\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1111\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 102 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 102 \n",
      "---\n",
      "val acc 0.280%\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.71\n",
      "| epoch 2 |  iter 21 / 351 | time 1[s] | loss 1.71\n",
      "| epoch 2 |  iter 41 / 351 | time 2[s] | loss 1.71\n",
      "| epoch 2 |  iter 61 / 351 | time 3[s] | loss 1.71\n",
      "| epoch 2 |  iter 81 / 351 | time 4[s] | loss 1.70\n",
      "| epoch 2 |  iter 101 / 351 | time 5[s] | loss 1.68\n",
      "| epoch 2 |  iter 121 / 351 | time 6[s] | loss 1.69\n",
      "| epoch 2 |  iter 141 / 351 | time 7[s] | loss 1.68\n",
      "| epoch 2 |  iter 161 / 351 | time 8[s] | loss 1.67\n",
      "| epoch 2 |  iter 181 / 351 | time 9[s] | loss 1.67\n",
      "| epoch 2 |  iter 201 / 351 | time 10[s] | loss 1.65\n",
      "| epoch 2 |  iter 221 / 351 | time 11[s] | loss 1.65\n",
      "| epoch 2 |  iter 241 / 351 | time 12[s] | loss 1.65\n",
      "| epoch 2 |  iter 261 / 351 | time 13[s] | loss 1.63\n",
      "| epoch 2 |  iter 281 / 351 | time 15[s] | loss 1.62\n",
      "| epoch 2 |  iter 301 / 351 | time 16[s] | loss 1.61\n",
      "| epoch 2 |  iter 321 / 351 | time 17[s] | loss 1.61\n",
      "| epoch 2 |  iter 341 / 351 | time 18[s] | loss 1.60\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1200\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 690 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 690 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 999 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1029\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1240\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 792 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 290 \n",
      "---\n",
      "val acc 0.400%\n",
      "| epoch 3 |  iter 1 / 351 | time 0[s] | loss 1.58\n",
      "| epoch 3 |  iter 21 / 351 | time 1[s] | loss 1.59\n",
      "| epoch 3 |  iter 41 / 351 | time 2[s] | loss 1.58\n",
      "| epoch 3 |  iter 61 / 351 | time 3[s] | loss 1.56\n",
      "| epoch 3 |  iter 81 / 351 | time 5[s] | loss 1.55\n",
      "| epoch 3 |  iter 101 / 351 | time 6[s] | loss 1.53\n",
      "| epoch 3 |  iter 121 / 351 | time 7[s] | loss 1.51\n",
      "| epoch 3 |  iter 141 / 351 | time 8[s] | loss 1.50\n",
      "| epoch 3 |  iter 161 / 351 | time 9[s] | loss 1.49\n",
      "| epoch 3 |  iter 181 / 351 | time 10[s] | loss 1.47\n",
      "| epoch 3 |  iter 201 / 351 | time 12[s] | loss 1.46\n",
      "| epoch 3 |  iter 221 / 351 | time 13[s] | loss 1.43\n",
      "| epoch 3 |  iter 241 / 351 | time 14[s] | loss 1.42\n",
      "| epoch 3 |  iter 261 / 351 | time 15[s] | loss 1.41\n",
      "| epoch 3 |  iter 281 / 351 | time 16[s] | loss 1.39\n",
      "| epoch 3 |  iter 301 / 351 | time 17[s] | loss 1.37\n",
      "| epoch 3 |  iter 321 / 351 | time 18[s] | loss 1.36\n",
      "| epoch 3 |  iter 341 / 351 | time 20[s] | loss 1.35\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 154 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1033\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 644 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 433 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 818 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1018\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1344\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 834 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 211 \n",
      "---\n",
      "val acc 1.600%\n",
      "| epoch 4 |  iter 1 / 351 | time 0[s] | loss 1.32\n",
      "| epoch 4 |  iter 21 / 351 | time 1[s] | loss 1.32\n",
      "| epoch 4 |  iter 41 / 351 | time 2[s] | loss 1.30\n",
      "| epoch 4 |  iter 61 / 351 | time 4[s] | loss 1.30\n",
      "| epoch 4 |  iter 81 / 351 | time 5[s] | loss 1.28\n",
      "| epoch 4 |  iter 101 / 351 | time 6[s] | loss 1.27\n",
      "| epoch 4 |  iter 121 / 351 | time 7[s] | loss 1.25\n",
      "| epoch 4 |  iter 141 / 351 | time 8[s] | loss 1.24\n",
      "| epoch 4 |  iter 161 / 351 | time 10[s] | loss 1.22\n",
      "| epoch 4 |  iter 181 / 351 | time 11[s] | loss 1.21\n",
      "| epoch 4 |  iter 201 / 351 | time 13[s] | loss 1.20\n",
      "| epoch 4 |  iter 221 / 351 | time 14[s] | loss 1.20\n",
      "| epoch 4 |  iter 241 / 351 | time 16[s] | loss 1.17\n",
      "| epoch 4 |  iter 261 / 351 | time 17[s] | loss 1.16\n",
      "| epoch 4 |  iter 281 / 351 | time 18[s] | loss 1.14\n",
      "| epoch 4 |  iter 301 / 351 | time 20[s] | loss 1.12\n",
      "| epoch 4 |  iter 321 / 351 | time 21[s] | loss 1.11\n",
      "| epoch 4 |  iter 341 / 351 | time 22[s] | loss 1.10\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1123\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 165 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 777 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1023\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1388\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 887 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 223 \n",
      "---\n",
      "val acc 5.140%\n",
      "| epoch 5 |  iter 1 / 351 | time 0[s] | loss 1.08\n",
      "| epoch 5 |  iter 21 / 351 | time 1[s] | loss 1.07\n",
      "| epoch 5 |  iter 41 / 351 | time 2[s] | loss 1.05\n",
      "| epoch 5 |  iter 61 / 351 | time 4[s] | loss 1.04\n",
      "| epoch 5 |  iter 81 / 351 | time 5[s] | loss 1.02\n",
      "| epoch 5 |  iter 101 / 351 | time 6[s] | loss 1.01\n",
      "| epoch 5 |  iter 121 / 351 | time 8[s] | loss 1.00\n",
      "| epoch 5 |  iter 141 / 351 | time 9[s] | loss 0.99\n",
      "| epoch 5 |  iter 161 / 351 | time 11[s] | loss 0.99\n",
      "| epoch 5 |  iter 181 / 351 | time 13[s] | loss 0.96\n",
      "| epoch 5 |  iter 201 / 351 | time 14[s] | loss 0.95\n",
      "| epoch 5 |  iter 221 / 351 | time 15[s] | loss 0.94\n",
      "| epoch 5 |  iter 241 / 351 | time 17[s] | loss 0.92\n",
      "| epoch 5 |  iter 261 / 351 | time 18[s] | loss 0.91\n",
      "| epoch 5 |  iter 281 / 351 | time 19[s] | loss 0.90\n",
      "| epoch 5 |  iter 301 / 351 | time 20[s] | loss 0.89\n",
      "| epoch 5 |  iter 321 / 351 | time 21[s] | loss 0.88\n",
      "| epoch 5 |  iter 341 / 351 | time 23[s] | loss 0.87\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1135\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 169 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 861 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1045\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1324\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "val acc 9.380%\n",
      "| epoch 6 |  iter 1 / 351 | time 0[s] | loss 0.90\n",
      "| epoch 6 |  iter 21 / 351 | time 1[s] | loss 0.86\n",
      "| epoch 6 |  iter 41 / 351 | time 2[s] | loss 0.83\n",
      "| epoch 6 |  iter 61 / 351 | time 3[s] | loss 0.84\n",
      "| epoch 6 |  iter 81 / 351 | time 4[s] | loss 0.82\n",
      "| epoch 6 |  iter 101 / 351 | time 5[s] | loss 0.81\n",
      "| epoch 6 |  iter 121 / 351 | time 6[s] | loss 0.80\n",
      "| epoch 6 |  iter 141 / 351 | time 8[s] | loss 0.79\n",
      "| epoch 6 |  iter 161 / 351 | time 9[s] | loss 0.78\n",
      "| epoch 6 |  iter 181 / 351 | time 10[s] | loss 0.77\n",
      "| epoch 6 |  iter 201 / 351 | time 11[s] | loss 0.76\n",
      "| epoch 6 |  iter 221 / 351 | time 13[s] | loss 0.76\n",
      "| epoch 6 |  iter 241 / 351 | time 14[s] | loss 0.74\n",
      "| epoch 6 |  iter 261 / 351 | time 16[s] | loss 0.74\n",
      "| epoch 6 |  iter 281 / 351 | time 17[s] | loss 0.73\n",
      "| epoch 6 |  iter 301 / 351 | time 18[s] | loss 0.72\n",
      "| epoch 6 |  iter 321 / 351 | time 19[s] | loss 0.72\n",
      "| epoch 6 |  iter 341 / 351 | time 20[s] | loss 0.71\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 858 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1048\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[91m☒\u001b[0m 873 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 239 \n",
      "---\n",
      "val acc 15.040%\n",
      "| epoch 7 |  iter 1 / 351 | time 0[s] | loss 0.68\n",
      "| epoch 7 |  iter 21 / 351 | time 1[s] | loss 0.69\n",
      "| epoch 7 |  iter 41 / 351 | time 2[s] | loss 0.67\n",
      "| epoch 7 |  iter 61 / 351 | time 3[s] | loss 0.66\n",
      "| epoch 7 |  iter 81 / 351 | time 4[s] | loss 0.66\n",
      "| epoch 7 |  iter 101 / 351 | time 5[s] | loss 0.65\n",
      "| epoch 7 |  iter 121 / 351 | time 7[s] | loss 0.65\n",
      "| epoch 7 |  iter 141 / 351 | time 8[s] | loss 0.64\n",
      "| epoch 7 |  iter 161 / 351 | time 9[s] | loss 0.63\n",
      "| epoch 7 |  iter 181 / 351 | time 10[s] | loss 0.61\n",
      "| epoch 7 |  iter 201 / 351 | time 11[s] | loss 0.61\n",
      "| epoch 7 |  iter 221 / 351 | time 12[s] | loss 0.60\n",
      "| epoch 7 |  iter 241 / 351 | time 13[s] | loss 0.57\n",
      "| epoch 7 |  iter 261 / 351 | time 14[s] | loss 0.57\n",
      "| epoch 7 |  iter 281 / 351 | time 16[s] | loss 0.57\n",
      "| epoch 7 |  iter 301 / 351 | time 17[s] | loss 0.55\n",
      "| epoch 7 |  iter 321 / 351 | time 18[s] | loss 0.54\n",
      "| epoch 7 |  iter 341 / 351 | time 19[s] | loss 0.53\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 156 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[91m☒\u001b[0m 858 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[91m☒\u001b[0m 1052\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 235 \n",
      "---\n",
      "val acc 39.100%\n",
      "| epoch 8 |  iter 1 / 351 | time 0[s] | loss 0.51\n",
      "| epoch 8 |  iter 21 / 351 | time 1[s] | loss 0.50\n",
      "| epoch 8 |  iter 41 / 351 | time 2[s] | loss 0.49\n",
      "| epoch 8 |  iter 61 / 351 | time 4[s] | loss 0.48\n",
      "| epoch 8 |  iter 81 / 351 | time 5[s] | loss 0.47\n",
      "| epoch 8 |  iter 101 / 351 | time 6[s] | loss 0.46\n",
      "| epoch 8 |  iter 121 / 351 | time 7[s] | loss 0.46\n",
      "| epoch 8 |  iter 141 / 351 | time 8[s] | loss 0.44\n",
      "| epoch 8 |  iter 161 / 351 | time 10[s] | loss 0.41\n",
      "| epoch 8 |  iter 181 / 351 | time 11[s] | loss 0.42\n",
      "| epoch 8 |  iter 201 / 351 | time 13[s] | loss 0.41\n",
      "| epoch 8 |  iter 221 / 351 | time 14[s] | loss 0.40\n",
      "| epoch 8 |  iter 241 / 351 | time 15[s] | loss 0.39\n",
      "| epoch 8 |  iter 261 / 351 | time 17[s] | loss 0.37\n",
      "| epoch 8 |  iter 281 / 351 | time 18[s] | loss 0.36\n",
      "| epoch 8 |  iter 301 / 351 | time 19[s] | loss 0.36\n",
      "| epoch 8 |  iter 321 / 351 | time 21[s] | loss 0.35\n",
      "| epoch 8 |  iter 341 / 351 | time 22[s] | loss 0.34\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 155 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[91m☒\u001b[0m 1438\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 65.060%\n",
      "| epoch 9 |  iter 1 / 351 | time 0[s] | loss 0.32\n",
      "| epoch 9 |  iter 21 / 351 | time 1[s] | loss 0.31\n",
      "| epoch 9 |  iter 41 / 351 | time 2[s] | loss 0.31\n",
      "| epoch 9 |  iter 61 / 351 | time 4[s] | loss 0.31\n",
      "| epoch 9 |  iter 81 / 351 | time 5[s] | loss 0.29\n",
      "| epoch 9 |  iter 101 / 351 | time 7[s] | loss 0.29\n",
      "| epoch 9 |  iter 121 / 351 | time 8[s] | loss 0.29\n",
      "| epoch 9 |  iter 141 / 351 | time 9[s] | loss 0.27\n",
      "| epoch 9 |  iter 161 / 351 | time 10[s] | loss 0.27\n",
      "| epoch 9 |  iter 181 / 351 | time 11[s] | loss 0.26\n",
      "| epoch 9 |  iter 201 / 351 | time 12[s] | loss 0.25\n",
      "| epoch 9 |  iter 221 / 351 | time 14[s] | loss 0.25\n",
      "| epoch 9 |  iter 241 / 351 | time 15[s] | loss 0.24\n",
      "| epoch 9 |  iter 261 / 351 | time 16[s] | loss 0.24\n",
      "| epoch 9 |  iter 281 / 351 | time 17[s] | loss 0.23\n",
      "| epoch 9 |  iter 301 / 351 | time 18[s] | loss 0.22\n",
      "| epoch 9 |  iter 321 / 351 | time 20[s] | loss 0.22\n",
      "| epoch 9 |  iter 341 / 351 | time 21[s] | loss 0.21\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[92m☑\u001b[0m 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 83.280%\n",
      "| epoch 10 |  iter 1 / 351 | time 0[s] | loss 0.22\n",
      "| epoch 10 |  iter 21 / 351 | time 1[s] | loss 0.20\n",
      "| epoch 10 |  iter 41 / 351 | time 2[s] | loss 0.20\n",
      "| epoch 10 |  iter 61 / 351 | time 3[s] | loss 0.20\n",
      "| epoch 10 |  iter 81 / 351 | time 4[s] | loss 0.18\n",
      "| epoch 10 |  iter 101 / 351 | time 6[s] | loss 0.17\n",
      "| epoch 10 |  iter 121 / 351 | time 7[s] | loss 0.18\n",
      "| epoch 10 |  iter 141 / 351 | time 8[s] | loss 0.17\n",
      "| epoch 10 |  iter 161 / 351 | time 9[s] | loss 0.17\n",
      "| epoch 10 |  iter 181 / 351 | time 10[s] | loss 0.17\n",
      "| epoch 10 |  iter 201 / 351 | time 11[s] | loss 0.17\n",
      "| epoch 10 |  iter 221 / 351 | time 12[s] | loss 0.16\n",
      "| epoch 10 |  iter 241 / 351 | time 14[s] | loss 0.15\n",
      "| epoch 10 |  iter 261 / 351 | time 15[s] | loss 0.15\n",
      "| epoch 10 |  iter 281 / 351 | time 16[s] | loss 0.15\n",
      "| epoch 10 |  iter 301 / 351 | time 17[s] | loss 0.15\n",
      "| epoch 10 |  iter 321 / 351 | time 18[s] | loss 0.14\n",
      "| epoch 10 |  iter 341 / 351 | time 19[s] | loss 0.14\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 656 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "\u001b[92m☑\u001b[0m 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "\u001b[92m☑\u001b[0m 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "\u001b[92m☑\u001b[0m 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "\u001b[92m☑\u001b[0m 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "\u001b[92m☑\u001b[0m 236 \n",
      "---\n",
      "val acc 88.400%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# Reverse input? =================================================\n",
    "is_reverse = True  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "# Normal or Peeky? ==============================================\n",
    "# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "\n",
    "# グラフの描画\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
